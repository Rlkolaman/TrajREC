{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ! pip install opencv-python\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "def parse_and_fuse_timestamp(time_str, time_nano):\n",
    "    # Parse the time string (e.g., \"2024-04-17 09:19:41\") and timeNano (e.g., \"322223\")\n",
    "    dt = datetime.strptime(f\"{time_str}_{time_nano.split('_')[-1]}\", \"%Y-%m-%d_%H_%M_%S_%f\")\n",
    "    return dt\n",
    "\n",
    "def process_pkl_files(meta_dir_root_dir, output_dir, background_image_name):\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Dictionary to store tracks, where each key is a Label and value is a list of detections\n",
    "    tracks = defaultdict(list)\n",
    "\n",
    "    # create a frame with the background image\n",
    "    background_image = cv2.imread(background_image_name)\n",
    "    # Iterate through all .pkl files in the Meta directory\n",
    "    meta_dir = os.path.join(meta_dir_root_dir, 'Meta')\n",
    "    list_of_pkl_files = os.listdir(meta_dir)\n",
    "    image_dir = os.path.join(meta_dir_root_dir, 'Images')\n",
    "    list_of_jpg_files = os.listdir(image_dir)\n",
    "    # max_x = 0\n",
    "    # max_y = 0\n",
    "    for pkl_indx, pkl_file in enumerate(list_of_pkl_files):\n",
    "        # background_image_copy = copy.deepcopy(background_image)\n",
    "        if pkl_file.endswith('.pkl') :\n",
    "            # frame_bbox_image = cv2.imread(os.path.join(image_dir, list_of_jpg_files[pkl_indx]))\n",
    "            pkl_path = os.path.join(meta_dir, pkl_file)\n",
    "            # Read the .pkl file\n",
    "            with open(pkl_path, 'rb') as f:\n",
    "                data = pkl.load(f)\n",
    "\n",
    "            # Extract required fields\n",
    "            label = data['Label']\n",
    "            if label == -10:\n",
    "                continue\n",
    "            time_nano = data['timeNano']\n",
    "            time = data['time']\n",
    "            box = data['BOX']\n",
    "\n",
    "            # Fuse time and timeNano for sorting\n",
    "            fused_timestamp = parse_and_fuse_timestamp(time, time_nano)\n",
    "\n",
    "            # change fused_timestamp to a counter in a resolution of 1/30 seconds from 1/1/1900\n",
    "            fused_timestamp = int((fused_timestamp - datetime(2023, 2, 9)).total_seconds() * 30)\n",
    "\n",
    "            # Convert BOX [x1, y1, x2, y2] to four points [x1, y1, x2, y1, x2, y2, x1, y2]\n",
    "            y1, x1, y2, x2 = [int(x) for x in box]\n",
    "            box_points = [x1, y1, x2, y1, x1, y2, x2, y2]\n",
    "            # if max_x < x2:\n",
    "            #     max_x = x2\n",
    "            # if max_y < y2:\n",
    "            #     max_y = y2\n",
    "            # #put the frame_bbox_image inside backjground_image at location of box_points\n",
    "            # background_image_copy[x1:x2, y1:y2] = frame_bbox_image\n",
    "            # cv2.imwrite(os.path.join(output_dir, background_image_name), background_image_copy)\n",
    "\n",
    "            # print(label)\n",
    "            # Append detection to the track for this Label\n",
    "            tracks[label].append({\n",
    "                'timestamp': fused_timestamp,\n",
    "                'box_points': box_points,\n",
    "                'source_file_name':pkl_file.split('.pkl')[0]\n",
    "                # 'background_image': background_image_copy\n",
    "            })\n",
    "            print(f'\\rprocessing pkl #{pkl_indx}/{len(list_of_pkl_files)}', end=\"\")\n",
    "\n",
    "    # print(f'max_y={max_y}')\n",
    "    # print(f'max_x = {max_x}')\n",
    "    # Process each track (Label) and save its detections to a CSV file\n",
    "    indx = 0\n",
    "    for label, detections in tracks.items():\n",
    "        indx+=1\n",
    "        print(f'\\rprocessing track #{indx}/{len(list_of_pkl_files)}', end=\"\")\n",
    "\n",
    "        # Sort detections by timestamp to ensure chronological order within the track\n",
    "        detections = sorted(detections, key=lambda x: x['timestamp'])\n",
    "\n",
    "        # Prepare data for CSV: each row is a detection in the track\n",
    "        csv_data = []\n",
    "        for i, detection in enumerate(detections, 0):  # 0-based index for detections\n",
    "            box_points = detection['box_points']\n",
    "            # Pad box points with zeros to reach 32 values\n",
    "            padded_points = box_points + [0.0] * (33 - len(box_points))\n",
    "            # Create row: detection index + box points + final zero\n",
    "            row = [detection['timestamp']] + padded_points + [0.0] + [detection['source_file_name']]\n",
    "            csv_data.append(row)\n",
    "\n",
    "        # Create a DataFrame without headers for the track\n",
    "        df = pd.DataFrame(csv_data)\n",
    "\n",
    "        # Define CSV filename (e.g., track_001.csv)\n",
    "        csv_filename = f\"1_{str(label).zfill(3)}.csv\"\n",
    "        csv_path = os.path.join(output_dir, csv_filename)\n",
    "\n",
    "        # Save the track's detections to CSV without headers\n",
    "        df.to_csv(csv_path, index=False, header=False)\n",
    "        print(f\"Saved track for label {label} to {csv_path} with {len(detections)} detections\")\n",
    "\n",
    "def main():\n",
    "    string_date = '2023_2_10'\n",
    "    # training_or_testing_str = 'training'\n",
    "    training_or_testing_str = 'testing'\n",
    "    # Define paths\n",
    "    meta_dir = '/home/pp/Desktop/datasets/elsec_dataset/frame/01/' + string_date + '/Pos'  # Path to Meta directory\n",
    "    output_dir = '/home/pp/Desktop/datasets/trajrec_data/elsec_data/'+ training_or_testing_str+'/trajectories/' + string_date  # Path to save CSV files\n",
    "    background_image_name = '/home/pp/Desktop/datasets/elsec_dataset/frame/01/elsec_road_meshulash_times_check.jpg'\n",
    "    # Process the .pkl files and save tracks\n",
    "    process_pkl_files(meta_dir, output_dir, background_image_name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ],
   "id": "84823a9264259b76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Read the label data\n",
    "# label_df = pd.read_csv('/home/pp/Desktop/datasets/trajrec_data/elsec_data/testing/trajectories/2023_2_10/1_116915.csv',\n",
    "#                        names=['time', 'x1', 'y1', 'x2', 'y2', 'x3', 'y3', 'x4', 'y4'],\n",
    "#                        delimiter='\\t')\n",
    "\n",
    "# Read anomaly data\n",
    "anomaly_df = pd.read_csv('/home/pp/Desktop/datasets/elsec_dataset/9-10_02_2023_elsec_road_meshulash/anomaly.csv')\n",
    "\n",
    "# Extract label from index column \n",
    "anomaly_df['label'] = anomaly_df['index'].str.extract(r'_(\\d+)_')\n",
    "\n",
    "# Print the loaded dataframes\n",
    "# print(\"Label data:\")\n",
    "# # print(label_df)\n",
    "# print(\"\\nAnomaly data:\")\n",
    "# print(anomaly_df)\n"
   ],
   "id": "8f5105b8ba37506a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# del label_df\n",
    "#"
   ],
   "id": "b24372a377048a4e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get list of trajectory files\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "trajectory_path = '/home/pp/Desktop/datasets/trajrec_data/elsec_data/testing/trajectories/2023_2_10/'\n",
    "trajectory_files = os.listdir(trajectory_path)\n",
    "\n",
    "# Initialize empty list to store all times \n",
    "all_times = []\n",
    "\n",
    "# Read each trajectory file and collect times\n",
    "for indx, file in enumerate(trajectory_files):\n",
    "    print(f\"\\rProcessing trajectory {indx + 1}/{len(trajectory_files)}\", end=\"\")\n",
    "    if file.endswith('.csv') and file.split('.csv')[0] !='-10':\n",
    "            df = pd.read_csv(os.path.join(trajectory_path, file),\n",
    "                             names=['time'] + [f'col{i}' for i in range(1, 36)],\n",
    "                             delimiter=',', index_col=False)\n",
    "\n",
    "            trajectory_id = file.split('.')[0]\n",
    "            times = df['time'].tolist()\n",
    "\n",
    "            # Check if this trajectory is in anomaly_df\n",
    "            is_anomaly = int(trajectory_id.split('_')[1] in anomaly_df['label'].values)\n",
    "\n",
    "            if is_anomaly == 1:\n",
    "                tst=1\n",
    "\n",
    "            # Add times with their anomaly status\n",
    "            all_times.extend([(t, is_anomaly) for t in times])\n",
    "\n",
    "# Create DataFrame from collected times and check for duplicates\n",
    "result_df = pd.DataFrame(all_times, columns=['frame_time', 'is_anomaly'])\n",
    "\n",
    "# Sort values and check duplicates  \n",
    "result_df = result_df.sort_values('frame_time')\n",
    "duplicates = result_df[result_df.duplicated(subset=['frame_time'], keep=False)]\n",
    "# print(\"Duplicate frame times:\")\n",
    "# print(duplicates)\n",
    "\n",
    "# Remove duplicates using boolean OR operation\n",
    "result_df = result_df.groupby('frame_time')['is_anomaly'].agg(lambda x: x.max() if any(x == 1) else 0).reset_index()\n",
    "\n",
    "# Display final sorted result\n",
    "print(\"\\nFinal sorted result without duplicates:\")\n",
    "print(result_df)\n"
   ],
   "id": "b8ec6938ecf87318",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "result_df.to_csv('/home/pp/Desktop/datasets/trajrec_data/elsec_data/testing/frame_level_masks/2023_2_10_result.csv', index=False)",
   "id": "b18fc2cf3ce7bc01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "result_df = pd.read_csv('/home/pp/Desktop/datasets/trajrec_data/elsec_data/testing/frame_level_masks/2023_2_10_result.csv')\n",
    "result_df.set_index('frame_time', inplace=True)\n",
    "\n",
    "trajectory_path = '/home/pp/Desktop/datasets/trajrec_data/elsec_data/testing/trajectories/2023_2_10/'\n",
    "trajectory_files = os.listdir(trajectory_path)\n",
    "\n",
    "for inde , file in enumerate(trajectory_files):\n",
    "    if file.endswith('.csv') and file != 'result.csv' and file.split('.csv')[0] != '-10':\n",
    "        print(f'{file} {inde} out of {len(trajectory_files)}')\n",
    "        # Read original CSV\n",
    "        df = pd.read_csv(os.path.join(trajectory_path, file),\n",
    "                         names=['time'] + [f'col{i}' for i in range(1, 36)],\n",
    "                         delimiter=',', index_col=False)\n",
    "\n",
    "        # Get the frame time values from result_df\n",
    "        frame_time_map = {time: pos for time, pos in zip(df['time'], result_df.index.get_indexer(df['time']))}\n",
    "\n",
    "        # Update the time column\n",
    "        df['time'] = df['time'].map(frame_time_map)\n",
    "\n",
    "        df = df.drop(df.columns[-1], axis=1)\n",
    "\n",
    "        # Write back to the same file\n",
    "        df.to_csv(os.path.join(trajectory_path, file), index=False, header=False)\n"
   ],
   "id": "dcf8d48c6586df01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.save('/home/pp/Desktop/datasets/trajrec_data/elsec_data/testing/frame_level_masks/2023_2_10/2023-2-10_1.npy',np.array(result_df.values).reshape(-1))\n",
   "id": "20a85297e8da0185",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
